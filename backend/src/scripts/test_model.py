import os
import argparse
import pickle
import pandas as pd
import google.generativeai as genai
from tensorflow import keras
from keras.models import load_model
from pdf_processing import extract_text_from_pdf
from requirement_extraction import extract_requirements_from_pdf
from io import StringIO
import time

# Constants
MAX_RETRIES = 3
RETRY_DELAY = 45  # seconds

# ==============================
# üîπ Load API key
# ==============================
genai.configure(api_key='AIzaSyAHBD3jHdaoYE3zikbDAkCx645jlmg2syc')

# ==============================
# üîπ Model setup with retry logic
# ==============================
MODEL_NAME = "models/gemini-1.5-flash-latest"
gemini_model = genai.GenerativeModel(MODEL_NAME)  # Avoids conflicts with Keras model

# ==============================
# üîπ Paths Setup
# ==============================
BASE_DIR = os.path.abspath(os.path.join(os.path.dirname(__file__), ".."))
UPLOADS_DIR = os.path.join(BASE_DIR, "uploads")
EXTRACTED_DIR = os.path.join(BASE_DIR, "extracted")
OUTPUT_DIR = os.path.abspath(os.path.join(BASE_DIR, "..", "output"))

MODEL_PATH = os.path.join(OUTPUT_DIR, "requirement_extraction_model.keras")
TOKENIZER_PATH = os.path.join(OUTPUT_DIR, "tokenizer.pkl")

# Ensure model and tokenizer exist
if not os.path.exists(MODEL_PATH):
    print(f"‚ùå ERROR: Model file NOT found at {MODEL_PATH}!")
    exit(1)

if not os.path.exists(TOKENIZER_PATH):
    print(f"‚ùå ERROR: Tokenizer file NOT found at {TOKENIZER_PATH}!")
    exit(1)

# ==============================
# üîπ Load TensorFlow Model & Tokenizer
# ==============================
print(f"‚úÖ Loading Keras model from {MODEL_PATH}...")
try:
    keras_model = load_model(MODEL_PATH)  # Use a separate variable
except Exception as e:
    print(f"‚ùå ERROR: Failed to load model: {e}")
    exit(1)

print(f"‚úÖ Loading tokenizer from {TOKENIZER_PATH}...")
try:
    with open(TOKENIZER_PATH, "rb") as f:
        tokenizer = pickle.load(f)
except Exception as e:
    print(f"‚ùå ERROR: Failed to load tokenizer: {e}")
    exit(1)

# ==============================
# üîπ Argument Parsing
# ==============================
parser = argparse.ArgumentParser(description="Process an SRS PDF and extract requirements.")
parser.add_argument("--file", required=True, help="Path to the SRS PDF file.")
parser.add_argument("--output", required=True, help="Path to save extracted CSV.")  
args = parser.parse_args()

# Validate PDF file
pdf_path = os.path.abspath(args.file)
if not os.path.exists(pdf_path):
    print(f"‚ùå ERROR: PDF file NOT found at {pdf_path}!")
    exit(1)

# ==============================
# üîπ Extract Text from PDF
# ==============================
print(f"üìÇ Processing: {pdf_path}")
srs_text = extract_text_from_pdf(pdf_path)

if not srs_text.strip():
    print(f"‚ö†Ô∏è WARNING: No text extracted from {pdf_path}")
    exit(1)

# ==============================
# üîπ Extract Requirements
# ==============================
print("üîç Extracting requirements...")
try:
    extracted_data = extract_requirements_from_pdf(pdf_path)
except Exception as e:
    print(f"‚ùå ERROR: Extraction function failed: {e}")
    exit(1)

if not extracted_data:
    print("‚ö†Ô∏è No requirements found in the document!")
    exit(1)

# ==============================
# üîπ Save Extracted Requirements to CSV
# ==============================
output_csv_path = os.path.abspath(args.output)
os.makedirs(os.path.dirname(output_csv_path), exist_ok=True)

# Convert the list of dictionaries to DataFrame
df = pd.DataFrame(extracted_data)
print(f"Debug: Original DataFrame columns: {df.columns}")

# Ensure we have the correct columns
if 'requirement' not in df.columns and 'Requirement Text' in df.columns:
    df = df.rename(columns={'Requirement Text': 'requirement'})
if 'label' not in df.columns:
    df['label'] = 'Functional'  # Default label
if 'filename' not in df.columns:
    df['filename'] = os.path.basename(args.file)

# Save initial CSV with all requirements
df.to_csv(output_csv_path, index=False, encoding='utf-8')
print(f"‚úÖ All requirements saved to: {output_csv_path}")

# Save only Functional requirements to updated file
updated_csv_path = output_csv_path.replace(".csv", "_updated.csv")
functional_reqs = df[df['label'] == 'Functional'].copy()
functional_reqs.to_csv(updated_csv_path, index=False, encoding='utf-8')
print(f"‚úÖ Functional requirements saved to: {updated_csv_path}")
print(f"üìä Summary: Found {len(functional_reqs)} functional requirements out of {len(df)} total requirements")
